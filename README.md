# üöÄ Handler RunPod pour Qwen-Image-Edit

Handler optimis√© pour l'essayage virtuel de v√™tements avec Qwen-Image-Edit sur RunPod.

## üìÅ Fichiers

- `handler.py` - Handler Python principal
- `Dockerfile` - Configuration Docker
- `requirements.txt` - D√©pendances Python
- `README.md` - Ce fichier

## üéØ Deux Options de D√©ploiement

### Option 1 : Via Docker Hub (Recommand√© - Plus Simple)

#### √âtape 1 : Build et Push l'Image

```bash
# Dans le dossier runpod-handler
cd "c:/Users/lamid/CascadeProjects/qwen image - Claude/runpod-handler"

# Build l'image
docker build -t votre-username/qwen-tryon:latest .

# Login Docker Hub
docker login

# Push l'image
docker push votre-username/qwen-tryon:latest
```

#### √âtape 2 : Cr√©er l'Endpoint sur RunPod

1. Allez sur https://www.runpod.io/console/serverless
2. Cliquez sur "+ New Endpoint"
3. S√©lectionnez "Docker Registry"
4. Image: `votre-username/qwen-tryon:latest`
5. Configuration:
   ```
   GPU: RTX 4090 (24GB)
   Workers Min: 0
   Workers Max: 1
   Container Disk: 30 GB
   Volume Disk: 50 GB
   Execution Timeout: 120s
   Idle Timeout: 5s
   ```

---

### Option 2 : Via GitHub (Plus Flexible)

#### √âtape 1 : Cr√©er un Repo GitHub

```bash
# Initialiser Git
cd "c:/Users/lamid/CascadeProjects/qwen image - Claude/runpod-handler"
git init

# Ajouter les fichiers
git add .
git commit -m "Initial commit: Qwen-Image-Edit handler"

# Cr√©er un repo sur GitHub et pusher
git remote add origin https://github.com/votre-username/qwen-tryon-handler.git
git branch -M main
git push -u origin main
```

#### √âtape 2 : Cr√©er l'Endpoint sur RunPod

1. Allez sur https://www.runpod.io/console/serverless
2. Cliquez sur "+ New Endpoint"
3. S√©lectionnez "Import from GitHub"
4. Repo: `votre-username/qwen-tryon-handler`
5. Branch: `main`
6. Dockerfile Path: `Dockerfile`
7. Configuration (m√™me que Option 1)

---

## üß™ Test Local (Optionnel)

### Pr√©requis
- Docker install√©
- GPU NVIDIA avec CUDA

### Commandes

```bash
# Build l'image
docker build -t qwen-tryon-local .

# Run localement
docker run --gpus all -p 8000:8000 qwen-tryon-local
```

---

## üìù Format d'Entr√©e

```json
{
  "input": {
    "image": "data:image/png;base64,...",
    "reference_image": "data:image/png;base64,...",
    "prompt": "Place this garment on the person naturally.",
    "strength": 0.8,
    "guidance_scale": 7.5
  }
}
```

## üì§ Format de Sortie

```json
{
  "output": {
    "image": "data:image/png;base64,...",
    "generated_text": "...",
    "prompt_used": "...",
    "status": "success"
  }
}
```

---

## ‚öôÔ∏è Configuration

### Variables d'Environnement

```bash
TRANSFORMERS_CACHE=/runpod-volume/transformers-cache
HF_HOME=/runpod-volume/huggingface
```

### Mod√®le Utilis√©

```python
MODEL_NAME = "Qwen/Qwen2-VL-7B-Instruct"
```

---

## üí° Optimisations

### 1. Pr√©-t√©l√©charger le Mod√®le

Dans le `Dockerfile`, d√©commentez:
```dockerfile
RUN python -c "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor; \
    processor = AutoProcessor.from_pretrained('Qwen/Qwen2-VL-7B-Instruct', trust_remote_code=True); \
    model = Qwen2VLForConditionalGeneration.from_pretrained('Qwen/Qwen2-VL-7B-Instruct', trust_remote_code=True)"
```

**Avantage:** D√©marrage plus rapide  
**Inconv√©nient:** Image Docker plus lourde (~15GB)

### 2. Utiliser un Volume Persistant

Sur RunPod, configurez un volume pour:
- Cache des mod√®les
- √âviter de re-t√©l√©charger √† chaque d√©marrage

---

## üêõ D√©pannage

### Erreur "Out of Memory"

**Solution:**
- Passez √† A40 (48GB)
- Ou r√©duisez la r√©solution des images dans le handler

### Erreur "Model not found"

**Solution:**
- V√©rifiez la connexion internet du pod
- Pr√©-t√©l√©chargez le mod√®le dans le Dockerfile

### Timeout

**Solution:**
- Augmentez `Execution Timeout` √† 180s
- Optimisez la taille des images

---

## üìä Performance

### Avec RTX 4090

- **Temps de chargement:** 30-60s (premi√®re fois)
- **Temps par image:** 15-25s
- **VRAM utilis√©e:** ~20GB
- **Co√ªt:** ~$0.003/image

---

## üîó Liens Utiles

- **Qwen GitHub:** https://github.com/QwenLM/Qwen-VL
- **Hugging Face:** https://huggingface.co/Qwen
- **RunPod Docs:** https://docs.runpod.io/

---

## ‚úÖ Checklist de D√©ploiement

- [ ] Fichiers cr√©√©s (handler.py, Dockerfile, requirements.txt)
- [ ] Docker install√© localement
- [ ] Compte Docker Hub cr√©√© (pour Option 1)
- [ ] Ou Repo GitHub cr√©√© (pour Option 2)
- [ ] Image build√©e et push√©e
- [ ] Endpoint cr√©√© sur RunPod
- [ ] Configuration GPU valid√©e
- [ ] Test effectu√©
- [ ] Endpoint ID copi√© dans `.env.local`

---

**üöÄ Pr√™t √† d√©ployer !**
